{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## winpython内部でyolov8_ocd仮想環境を作成（コマンドプロンプト使用）\\\n",
    "python -m venv [仮想環境名　今回はyolov5_ocd]\\\n",
    "yolov8_ocdフォルダが作成されるので\\(Scriptsフォルダに作成されるかも)\n",
    "cd yolov8_ocdで移動して\\\n",
    "Scripts\\activate　で仮想環境を起動するとコマンドプロンプトがこの様になるはず\\\n",
    "(yolov8_ocd) D:\\WPy64-31090\\yolov8_ocd>\\　みたいになればOK\n",
    "codeでVScodeを起動　カーネルが仮想環境カーネルとなっている事を確認\\"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\WPy64-31090\\scripts\\yolov8_ocd\\ultralytics\n"
     ]
    }
   ],
   "source": [
    "#VS codeの中で現在のディレクトリを確認\n",
    "import os\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#yolov8フォルダに移動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\WPy64-31090\\scripts\\yolov8_ocd\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ultralyticsのフォルダをクローンしてくる\n",
    "!git clone https://github.com/ultralytics/ultralytics\n",
    "%cd ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#必要なライブラリをインストールする\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysimplegui\n",
      "  Using cached PySimpleGUI-4.60.4-py3-none-any.whl (509 kB)\n",
      "Installing collected packages: pysimplegui\n",
      "Successfully installed pysimplegui-4.60.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#pysimpleGUIをインストール\n",
    "!pip install pysimplegui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yolov8の動作確認\n",
    "https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/zidane.jpg\n",
    "ジダンの画像をダウンロードしてカレントディレクトリに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\WPy64-31090\\\\scripts\\\\yolov8_ocd\\\\ultralytics'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"D:/WPy64-31090/scripts/yolov8_ocd/ultralytics\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\WPy64-31090\\scripts\\yolov8_ocd\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Ultralytics YOLOv8.0.46  Python-3.10.9 torch-1.13.1+cpu CPU\n",
      "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n",
      "\n",
      "image 1/1 D:\\WPy64-31090\\scripts\\yolov8_ocd\\ultralytics\\zidane.jpg: 384x640 1 person, 1580.1ms\n",
      "Speed: 2.0ms preprocess, 1580.1ms inference, 17.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "#試験検出　学習済みモデルはyolov8xとする　最初はダウンロードに時間がかかる\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8x.pt\") \n",
    "results = model('zidane.jpg',save=False,save_txt=False,max_det=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcameraからの推論\n",
    "#高速化のためにyoov8nを使用\n",
    "#ocdを検出するときは訓練済みのptモデルをyolov8/ultralyticsフォルダにおいてmodel=''で名前を指定する\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "from ultralytics.yolo.data.augment import LetterBox\n",
    "from ultralytics.yolo.utils.plotting import Annotator, colors\n",
    "from ultralytics.yolo.utils import ops\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "#ocd検出モデルを読み込む場合\n",
    "#model = YOLO(\"tolov8n_ocd\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "def preprocess(img, size=640):\n",
    "        img = LetterBox(size, True)(image=img)\n",
    "        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        img = np.ascontiguousarray(img)  # contiguous\n",
    "        img = torch.from_numpy(img)\n",
    "        img = img.float()  # uint8 to fp16/32\n",
    "        img /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        return img.unsqueeze(0)\n",
    "\n",
    "def postprocess(preds, img, orig_img):\n",
    "    preds = ops.non_max_suppression(preds,\n",
    "                                    0.25,\n",
    "                                    0.8,\n",
    "                                    agnostic=False,\n",
    "                                    max_det=100)\n",
    "\n",
    "    for i, pred in enumerate(preds):\n",
    "        shape = orig_img.shape\n",
    "        pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], shape).round()\n",
    "\n",
    "    return preds\n",
    "\n",
    "def drow_bbox(pred, names, annotator):\n",
    "    for *xyxy, conf, cls in reversed(pred):\n",
    "        c = int(cls)  # integer class\n",
    "        label =  f'{names[c]} {conf:.2f}'\n",
    "        annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    origin = deepcopy(img)\n",
    "    #imageを小さくする\n",
    "    origin = cv2.resize(origin, (640,480))\n",
    "    annotator = Annotator(origin,line_width=3,example=str(model.model.names))\n",
    "    img = preprocess(img)\n",
    "    preds = model.model(img, augment=False)\n",
    "    preds = postprocess(preds,img,origin)\n",
    "    drow_bbox(preds[0], model.model.names, annotator)\n",
    "    cv2.imshow(\"test\",origin)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break  # q キーを押したら終了する。\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##pysimple GUI   をつかってGUI化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width x height = 1500 x 1000 (pixels)\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "monitor_height = root.winfo_screenheight()\n",
    "monitor_width = root.winfo_screenwidth()\n",
    "  \n",
    "print(\"width x height = %d x %d (pixels)\" %(monitor_width, monitor_height))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネルがクラッシュしました。エラーの原因を特定するには、セル内のコードを確認してください。詳細については、<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a> をクリックしてください。さらなる詳細については、Jupyter [log] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "#cocomodelを読み込む場合\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "#ocd検出モデルを読み込む場合\n",
    "#model = YOLO(\"yolov8n_ocd.pt\")\n",
    "\n",
    "#torchhubモデルの検出時のパラメーター設定\n",
    "\"\"\"model.conf=0.4\n",
    "model.iou=0.45\n",
    "model.multi_label=False\n",
    "model.max_det=5\"\"\"\n",
    "\n",
    "import PySimpleGUI as sg\n",
    "#すべての警告の非表示\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#value = [0, 1, 2]#cameraの番号設定\n",
    "threshould=0.4 #閾値の初期設定\n",
    "#カメラ番号入力のポップアップ 外部入力なら1か2\n",
    "cameranum = sg.popup_get_text(\"input camera number(0,1,2)\", title=\"camera number\", default_text=\"1\")\n",
    "cameranum =int(cameranum)\n",
    "\n",
    "#GUIの初期設定\n",
    "sg.theme('DarkBlue15')\n",
    "layout = [\n",
    "   [sg.Image(key='img1',), sg.Image(key='img2',)],\n",
    "   #[[sg.Text('select camera'),sg.Listbox(value, size=(10, 3),key=('cameranum'))]],\n",
    "   [[sg.Text('confidence thredshold'),sg.Slider(range=(0.1,1.0),default_value=0.4, resolution=0.1 ,orientation='h',\n",
    "   size=(20,2),enable_events=True, key='slider',)]],\n",
    "    [[sg.Button('Start', size=(10, 1)), sg.Button('Stop', size=(10,1))]],\n",
    "\n",
    "    [sg.Button('Exit', size=(10, 1))],]\n",
    "#記録イベントのためにstartedという関数を定義               \n",
    "started= False\n",
    "#webカメラで検出\n",
    "import cv2\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "#camera = cv2.VideoCapture('./data/images/ocd.mp4')\n",
    "#pysimpleGUIのwindow定義\n",
    "window = sg.Window(\"webカメラ画面\", location=(100,100),layout=layout, size=(monitor_width,monitor_height),resizable=True,finalize=True)\n",
    "event, values = window.read(timeout=20)\n",
    "#cameranum = int(values['cameranum'])\n",
    "#if event == ['caneranum']:\n",
    "#    cameranum=int(values['cameranum'])\n",
    "cap = cv2.VideoCapture(cameranum) #外部入力カメラを使用する場合0を1に変更\n",
    "# ビデオ記録用の変数定義\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('result_{}.mp4'.format(dt.datetime.now()), fourcc, fps, (width, height))\n",
    "while True:\n",
    "    ret, imgs = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    #imageを小さくする\n",
    "    imgs = cv2.resize(imgs, (int(monitor_width/2),int(monitor_height/2)))\n",
    "    h,w,ch=imgs.shape\n",
    "# キャプチャーした画像をpngに変換\n",
    "    image1 = cv2.imencode('.png', imgs)[1].tobytes()                   \n",
    "# Imageの内容を更新\n",
    "    window['img1'].update(data=image1)#web cameraの画像を直接表示\n",
    "    event, values = window.read(timeout=0)\n",
    "    \"\"\"if event == ['caneranum']:\n",
    "        cameranum=int(values['cameranum'])\n",
    "        cap=cv2.VideoCapture(cameranum)\n",
    "        ret,img = cap.read()\"\"\"\n",
    "\n",
    "    if values['slider']:\n",
    "      threshould=values['slider']\n",
    "      model.conf=threshould\n",
    "\n",
    "    if event == 'Start':\n",
    "        started = True\n",
    "    if started == True:\n",
    "        #画面を10*10分割して1/10のところから9/10のところまで切り抜き\n",
    "        im_cropped=imgs[round(h/10):round(h/10)*9, round(w/10):round(w/10)*9,:]\n",
    "        #切り抜いた画像をモニターのサイズに合わせて拡大\n",
    "        im_cropped=cv2.resize(im_cropped,(int(monitor_width/2),int(monitor_height/2)))\n",
    "        #切り抜いた画像に対して推論\n",
    "        origin = deepcopy(im_cropped)\n",
    "        annotator = Annotator(origin,line_width=3,example=str(model.model.names))\n",
    "        img = preprocess(im_cropped)\n",
    "        preds = model.model(img, augment=False)\n",
    "        preds = postprocess(preds,img,origin)\n",
    "        drow_bbox(preds[0], model.model.names, annotator)       \n",
    "    # キャプチャーした画像をpngに変換\n",
    "        image2 = cv2.imencode('.png', origin)[1].tobytes()\n",
    "    # Imageの内容を更新\n",
    "        window['img2'].update(data=image2)       \n",
    "\n",
    "    if event =='Stop':\n",
    "        started = False\n",
    "        out.release()\n",
    "\n",
    "    if event == 'Exit' or event == sg.WIN_CLOSED:\n",
    "        break\n",
    "\n",
    "cap.release()    \n",
    "window.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_ocd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55f737adf709cc9a8cfb87023ad860c31cdf2ef29dfdfc62725bcd843f000328"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
