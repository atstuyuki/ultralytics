{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## winpythonの直下にyolov8_ocdフォルダを作成しておく\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## githubからクローンするかZIPをダウンロード\n",
    "https://github.com/atstuyuki/ultralytics\n",
    "のZIPフォルダをダウンロードして解凍し、中身をすべてyolov8フォルダに移す"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\WPy64-31090\\yolov8\n"
     ]
    }
   ],
   "source": [
    "#VS codeの中で現在のディレクトリを確認\n",
    "#yolov8フォルダに移動\n",
    "import os\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリをインストール初回のみ実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.24.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (4.7.0.72)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (9.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (1.13.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 13)) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 14)) (4.64.1)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 17)) (2.12.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 22)) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 23)) (0.12.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 38)) (5.9.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 39)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: certifi>=2022.12.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 44)) (2022.12.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (4.38.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.0.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\miniconda3\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 14)) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (65.6.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.2.3)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.51.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.38.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\user\\miniconda3\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.22.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 22)) (2022.7.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "#必要なライブラリをインストールする\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysimplegui in c:\\users\\user\\miniconda3\\lib\\site-packages (4.60.4)\n"
     ]
    }
   ],
   "source": [
    "#pysimpleGUIをインストール\n",
    "!pip install pysimplegui"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yolov8の動作確認\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniconda3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Ultralytics YOLOv8.0.47  Python-3.10.9 torch-1.13.1+cpu CPU\n",
      "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n",
      "\n",
      "image 1/1 C:\\Users\\User\\Desktop\\WPy64-31090\\yolov8\\zidane.jpg: 384x640 2 persons, 1 tie, 1916.1ms\n",
      "Speed: 5.0ms preprocess, 1916.1ms inference, 25.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "#試験検出　学習済みモデルはyolov8xとする　最初はダウンロードに時間がかかる\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8x.pt\") \n",
    "results = model('zidane.jpg',save=False,save_txt=False,max_det=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pysimpleGUIによるwebカメラからの検出\n",
    "# 最初にカメラ番号(0,1,2 のどれか)を半角数字で入力\n",
    "# 続いて学習済みモデルを選択　(xxx.ptとなっているファイル)\n",
    "# startで検出開始　thresholdで検出閾値変更　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.47  Python-3.10.9 torch-1.13.1+cpu CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "0: 448x640 1 person, 202.4ms\n",
      "Speed: 2.0ms preprocess, 202.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 191.1ms\n",
      "Speed: 1.0ms preprocess, 191.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 book, 189.1ms\n",
      "Speed: 1.0ms preprocess, 189.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 189.1ms\n",
      "Speed: 1.0ms preprocess, 189.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 193.1ms\n",
      "Speed: 2.0ms preprocess, 193.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 188.4ms\n",
      "Speed: 1.0ms preprocess, 188.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 174.5ms\n",
      "Speed: 1.0ms preprocess, 174.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 198.1ms\n",
      "Speed: 1.0ms preprocess, 198.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 book, 188.3ms\n",
      "Speed: 1.0ms preprocess, 188.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 197.4ms\n",
      "Speed: 1.0ms preprocess, 197.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 book, 204.0ms\n",
      "Speed: 1.0ms preprocess, 204.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 196.0ms\n",
      "Speed: 3.0ms preprocess, 196.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 198.1ms\n",
      "Speed: 1.0ms preprocess, 198.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 189.9ms\n",
      "Speed: 1.0ms preprocess, 189.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 189.1ms\n",
      "Speed: 0.0ms preprocess, 189.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 185.0ms\n",
      "Speed: 1.0ms preprocess, 185.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 185.2ms\n",
      "Speed: 2.0ms preprocess, 185.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 186.0ms\n",
      "Speed: 1.0ms preprocess, 186.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 183.1ms\n",
      "Speed: 1.0ms preprocess, 183.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 191.4ms\n",
      "Speed: 1.0ms preprocess, 191.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 182.0ms\n",
      "Speed: 2.0ms preprocess, 182.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 184.5ms\n",
      "Speed: 1.5ms preprocess, 184.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 187.0ms\n",
      "Speed: 1.0ms preprocess, 187.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 251.5ms\n",
      "Speed: 1.0ms preprocess, 251.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 185.5ms\n",
      "Speed: 1.0ms preprocess, 185.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 180.9ms\n",
      "Speed: 1.0ms preprocess, 180.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 179.1ms\n",
      "Speed: 3.0ms preprocess, 179.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 194.1ms\n",
      "Speed: 2.0ms preprocess, 194.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 175.5ms\n",
      "Speed: 1.0ms preprocess, 175.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 188.1ms\n",
      "Speed: 1.0ms preprocess, 188.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 cell phone, 188.0ms\n",
      "Speed: 1.0ms preprocess, 188.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 181.3ms\n",
      "Speed: 1.0ms preprocess, 181.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 book, 189.1ms\n",
      "Speed: 2.0ms preprocess, 189.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 197.3ms\n",
      "Speed: 2.0ms preprocess, 197.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 192.1ms\n",
      "Speed: 2.0ms preprocess, 192.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 179.1ms\n",
      "Speed: 3.0ms preprocess, 179.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 book, 235.7ms\n",
      "Speed: 2.0ms preprocess, 235.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 book, 200.4ms\n",
      "Speed: 2.0ms preprocess, 200.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 book, 191.6ms\n",
      "Speed: 1.0ms preprocess, 191.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのimport\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics.yolo.data.augment import LetterBox\n",
    "from ultralytics.yolo.utils.plotting import Annotator, colors\n",
    "from ultralytics.yolo.utils import ops\n",
    "#from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PySimpleGUI as sg\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "#すべての警告の非表示\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from tkinter import *\n",
    "#tkinterでモニタのサイズを取得\n",
    "root = Tk()\n",
    "monitor_height = root.winfo_screenheight()\n",
    "monitor_width = root.winfo_screenwidth()\n",
    "root.withdraw()\n",
    "\n",
    "#閾値の初期設定\n",
    "threshould = 0.4 \n",
    "\n",
    "#カメラ番号入力のポップアップ 外部入力なら1か2\n",
    "cameranum = sg.popup_get_text(\"input camera number(0,1,2)\", title=\"camera number\", default_text=\"1\")\n",
    "cameranum =int(cameranum)\n",
    "\n",
    "# 動作させる学習済みモデルを選択\n",
    "model = sg. popup_get_file(\"学習済みモデル(xxx.pt)を選択\")\n",
    "model = os.path.basename(model)\n",
    "sg.popup(model)\n",
    "\n",
    "#GUIの初期設定\n",
    "sg.theme('DarkBlue15')\n",
    "layout = [\n",
    "   [sg.Image(key='img1',), sg.Image(key='img2',)],\n",
    "   #[[sg.Text('select model'),sg.Listbox(model_list, size=(10, 3),key=('model_list'))]],\n",
    "\n",
    "   [[sg.Text('confidence thredshold'),sg.Slider(range=(0.1,1.0),default_value=0.4, resolution=0.1 ,orientation='h',\n",
    "   size=(20,2),enable_events=True, key='slider',)]],\n",
    "    [[sg.Button('Start', size=(10, 1)), sg.Button('Stop', size=(10,1))]],\n",
    "\n",
    "    [sg.Button('Exit', size=(10, 1))],]\n",
    "\n",
    "#記録イベントのためにstartedという関数を定義               \n",
    "started= False\n",
    "\n",
    "#webカメラで検出\n",
    "#pysimpleGUIのwindow定義 windowサイズはモニタサイズから自動取得\n",
    "\n",
    "window = sg.Window(\"webカメラ画面\", location=(100,100),layout=layout, size=(monitor_width,monitor_height),resizable=True,finalize=True)\n",
    "event, values = window.read(timeout=20)\n",
    "\n",
    "cap = cv2.VideoCapture(cameranum) #外部入力カメラを使用する場合0を1に変更\n",
    "# ビデオ記録用の変数定義\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('result_{}.mp4'.format(dt.datetime.now()), fourcc, fps, (width, height))\n",
    "model = YOLO(model)\n",
    "while True:\n",
    "    ret, imgs = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    #imageを小さくする\n",
    "    imgs = cv2.resize(imgs, (int(monitor_width/2),int(monitor_height/2)))\n",
    "    h,w,ch=imgs.shape\n",
    "# キャプチャーした画像をpngに変換\n",
    "    image1 = cv2.imencode('.png', imgs)[1].tobytes()                   \n",
    "# Imageの内容を更新\n",
    "    window['img1'].update(data=image1)#web cameraの画像を直接表示\n",
    "    event, values = window.read(timeout=0)\n",
    "\n",
    "    if values['slider']:\n",
    "      threshould=values['slider']\n",
    "    \n",
    "\n",
    "    if event == 'Start':\n",
    "        started = True\n",
    "    if started == True:\n",
    "        #画面を10*10分割して1/10のところから9/10のところまで切り抜き\n",
    "        im_cropped=imgs[round(h/10):round(h/10)*9, round(w/10):round(w/10)*9,:]\n",
    "        #切り抜いた画像をモニターのサイズに合わせて拡大\n",
    "        im_cropped=cv2.resize(im_cropped,(int(monitor_width/2),int(monitor_height/2)))\n",
    "        #切り抜いた画像に対して推論\n",
    "        preds = model(im_cropped, conf=threshould)\n",
    "        #この操作で推論結果をnaddaryに変換して画像表示\n",
    "        preds_plotted = preds[0].plot()\n",
    "    # キャプチャーした画像をpngに変換\n",
    "        image2 = cv2.imencode('.png', preds_plotted)[1].tobytes()\n",
    "    # Imageの内容を更新\n",
    "        window['img2'].update(data=image2)       \n",
    "\n",
    "    if event =='Stop':\n",
    "        started = False\n",
    "        out.release()\n",
    "\n",
    "    if event == 'Exit' or event == sg.WIN_CLOSED:\n",
    "        break\n",
    "\n",
    "cap.release()    \n",
    "window.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8_ocd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55f737adf709cc9a8cfb87023ad860c31cdf2ef29dfdfc62725bcd843f000328"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
